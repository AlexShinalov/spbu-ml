{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!unzip /content/drive/MyDrive/one-piece-classification-2025.zip -d /content/data"
      ],
      "metadata": {
        "id": "XCUCxInFMsxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOY87yuKTKyG",
        "outputId": "b820db7d-f524-42af-9c73-9e4838904652"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import efficientnet_b3, EfficientNet_B3_Weights\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "Dvv8hwovTQ8n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Основная идея:**\n",
        "\n",
        "1) Взять готовую модель EfficientNet\n",
        "2) Обучить классификатор на своих данных\n",
        "3) Произвести полный fine-tuning\n",
        "\n",
        "**Гипотеза:**\n",
        "\n",
        "Классфикатор обучится быстро и стабильно, что не сломает сложные слои. Малый размер датасета может привести к переобучению и оверфиттингу.\n",
        "\n",
        "В первом случае берем больший lr, тк шанс все поломать низкий"
      ],
      "metadata": {
        "id": "BEepyg54YZtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dir = \"/content/data/splitted/train\"\n",
        "test_dir = \"/content/data/splitted/test\"\n"
      ],
      "metadata": {
        "id": "-tH5blSjUYUY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = datasets.ImageFolder(root=train_dir)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "image_paths = [path for path, label in full_dataset.samples]\n",
        "labels = [label for path, label in full_dataset.samples]\n",
        "\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cYxtTfiP6jG",
        "outputId": "19c2d2ff-d310-4433-f5a5-d47c1a941c0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 2623, Val: 292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = EfficientNet_B3_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_b3(weights=weights)"
      ],
      "metadata": {
        "id": "WDrJ00v7beyt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Кастомные трансформации\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),       # небольшое изменение размера для последующего кропа\n",
        "    transforms.CenterCrop(224),   # центрируем до 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "# Создаем объекты датасетов\n",
        "train_dataset = ImageDataset(train_paths, train_labels, transform=train_transforms)\n",
        "val_dataset   = ImageDataset(val_paths,   val_labels,   transform=val_transforms)\n"
      ],
      "metadata": {
        "id": "zImeHsqGWy_b"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.manual_seed(42)\n",
        "if device.type == 'cuda':\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.backends.cudnn.benchmark = True  # оптимизация CUDA для повторяющихся размеров\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa1HWvZvXVsH",
        "outputId": "dfaa6c0f-f5cc-4b7a-a87b-e2a4178b23b0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Заменяем последний классификатор\n",
        "in_features = model.classifier[1].in_features  # число входов последнего слоя\n",
        "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "print(model.classifier)\n",
        "\n",
        "# Замораживаем все слои кроме последнего\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# обучаем только параметры классификатора\n",
        "optimizer_stage1 = torch.optim.AdamW(model.classifier[1].parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htrlLso8YIaj",
        "outputId": "73568c8e-fa4c-4e6e-99c7-5b9c329c59ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.3, inplace=True)\n",
            "  (1): Linear(in_features=1536, out_features=18, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, optimizer, criterion, device, scaler=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    # Если используется смешанная точность, scaler должен быть передан\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Автоматическая смешанная точность\n",
        "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "        # Обратное распространение с GradScaler, если он задан\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            # Предсказанные классы:\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(targets.cpu().numpy())\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "\n",
        "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    return epoch_loss, epoch_f1\n"
      ],
      "metadata": {
        "id": "teJy5Ey0YV8F"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучение только последнего слоя\n",
        "epochs_stage1 = 3\n",
        "scaler = torch.amp.GradScaler(\"cuda\") if device.type == \"cuda\" else None\n",
        "\n",
        "best_f1 = 0.0\n",
        "for epoch in range(1, epochs_stage1+1):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer_stage1, criterion, device, scaler)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch}/{epochs_stage1} - \"f\"Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "      best_f1 = val_f1\n",
        "      best_state = copy.deepcopy(model.state_dict())\n",
        "      best_epoch = epoch\n",
        "print(best_f1)\n"
      ],
      "metadata": {
        "id": "5Vs1Qj9vYcdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# размораживаем все слои и настраиваем оптимизатор для fine-tuning всей модели\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer_stage2 = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scaler = torch.cuda.amp.GradScaler() if device.type == 'cuda' else None\n",
        "\n",
        "patience = 5\n",
        "wait = 0\n",
        "best_f1_stage2 = best_f1\n",
        "best_state_stage2 = best_state.copy()\n",
        "best_epoch_stage2 = 0\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer_stage2, criterion, device, scaler)\n",
        "    val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "    print(f\"Epoch {epoch} - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Val F1: {val_f1:.4f}\")\n",
        "    if val_f1 > best_f1_stage2:\n",
        "        # Улучшение на валидации - сохраняем модель\n",
        "        best_f1_stage2 = val_f1\n",
        "        best_state_stage2 = model.state_dict().copy()\n",
        "        best_epoch_stage2 = epoch\n",
        "        wait = 0\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Выход на плато\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "_574p82UZSp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# лучшие веса модели\n",
        "model.load_state_dict(best_state_stage2)\n",
        "print(f\"Лучшая эпоха{best_epoch_stage2}\")\n",
        "\n",
        "# финальная оценка на валидации с лучшими весами\n",
        "val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "print(f\" {val_f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "-p7bOrTBce9w",
        "outputId": "04051cdf-6065-4543-a088-37a4eabb8f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая эпоха17\n",
            " 0.9171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, image_ids, image_dir, transform=None):\n",
        "        self.image_ids = image_ids\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.extensions = [\"\", \".png\", \".jpg\", \".jpeg\", \".JPG\", \".JPEG\", \".PNG\"]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = str(self.image_ids[idx])\n",
        "\n",
        "        # доработка для расширений\n",
        "        image_path = None\n",
        "        for ext in self.extensions:\n",
        "            trial = os.path.join(self.image_dir, img_id + ext)\n",
        "            if os.path.exists(trial):\n",
        "                image_path = trial\n",
        "                break\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_id\n",
        "\n",
        "\n",
        "def make_submission_csv(\n",
        "    model,\n",
        "    best_state,\n",
        "    test_dir,\n",
        "    sample_submission_path=\"sample_submission.csv\",\n",
        "    output_path=\"submission.csv\",\n",
        "    transform=None,\n",
        "    batch_size=32,\n",
        "):\n",
        "    index_to_class = {\n",
        "        0: \"Ace\",\n",
        "        1: \"Akainu\",\n",
        "        2: \"Brook\",\n",
        "        3: \"Chopper\",\n",
        "        4: \"Crocodile\",\n",
        "        5: \"Franky\",\n",
        "        6: \"Jinbei\",\n",
        "        7: \"Kurohige\",\n",
        "        8: \"Law\",\n",
        "        9: \"Luffy\",\n",
        "        10: \"Mihawk\",\n",
        "        11: \"Nami\",\n",
        "        12: \"Rayleigh\",\n",
        "        13: \"Robin\",\n",
        "        14: \"Sanji\",\n",
        "        15: \"Shanks\",\n",
        "        16: \"Usopp\",\n",
        "        17: \"Zoro\"\n",
        "    }\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # шаблон submission\n",
        "    sub_df = pd.read_csv(sample_submission_path)\n",
        "    id_col = sub_df.columns[0]\n",
        "    label_col = sub_df.columns[1]\n",
        "\n",
        "    image_ids = sub_df[id_col].tolist()\n",
        "\n",
        "    test_dataset = TestDataset(image_ids=image_ids, image_dir=test_dir, transform=transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, ids in test_loader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds_idx = outputs.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "            for p in preds_idx:\n",
        "                predictions.append(p)\n",
        "\n",
        "    # сохраняем предсказания\n",
        "    sub_df[label_col] = predictions\n",
        "    sub_df.to_csv(output_path, index=False)\n",
        "\n",
        "    print(f\"submission файл создан: {output_path}\")\n"
      ],
      "metadata": {
        "id": "a1qkHvUDfyS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_submission_csv(\n",
        "    model=model,\n",
        "    best_state=best_state_stage2,\n",
        "    test_dir=test_dir,\n",
        "    sample_submission_path=\"data/submission.csv\",\n",
        "    output_path=\"submission_1.csv\",\n",
        "    transform=val_transforms,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGgMZK2tfzV7",
        "outputId": "636237fc-b513-4683-d2ef-31b10a70064f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission файл создан: submission_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/data/splitted/test/88f6f8c2-d752-4876-b3c0-a5407ecd30f3.png"
      ],
      "metadata": {
        "id": "FTKLwWeoia6A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}